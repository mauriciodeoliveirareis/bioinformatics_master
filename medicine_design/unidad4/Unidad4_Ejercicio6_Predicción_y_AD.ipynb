{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72f3bd2",
   "metadata": {},
   "source": [
    "# Módulo 4: Modelo de clasificación QSAR (paso a paso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e03065",
   "metadata": {},
   "source": [
    "En este módulo desarrollaremos nuestro primer modelo QSAR, concretamente un modelo para la toxicidad aguda en lombrices de tierra. Dado que desarrollar un modelo QSAR implica un flujo de trabajo con varios pasos y este es tu primer modelo, este módulo será extenso, ya que exploraremos cada paso cuidadosamente. Por ello, el flujo de trabajo se divide en diferentes lecciones, y la práctica en Python correspondiente está separada en distintos archivos Jupyter Notebook. Como recordatorio, en este curso el flujo de trabajo para desarrollar un modelo QSAR se divide en las siguientes partes:\n",
    "\n",
    "- Parte 1: Obtención y depuración de datos\n",
    "- Parte 2: Cálculo de descriptores moleculares\n",
    "- Parte 3: División entre entrenamiento y prueba, y estandarización\n",
    "- Parte 4: Selección de descriptores\n",
    "- Parte 5: Desarrollo y optimización del modelo\n",
    "- Parte 6: Predicción y dominio de aplicabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c5c4e",
   "metadata": {
    "id": "6f4c5c4e"
   },
   "source": [
    "# Parte 6: Predicción y dominio de aplicabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XsrTRDZW5MjP",
   "metadata": {
    "id": "XsrTRDZW5MjP"
   },
   "source": [
    "En esta lección aprenderemos cómo realizar una predicción con nuestro modelo optimizado y utilizaremos diferentes métodos para evaluar si la sustancia predicha se encuentra dentro del espacio químico del modelo (es decir, dentro de su dominio de aplicabilidad).\n",
    "\n",
    "Primero, leeremos un modelo optimizado y comprobaremos que es el modelo que queremos utilizar [Sección 1].\n",
    "\n",
    "En segundo lugar, realizaremos una predicción para una molécula de ejemplo: la cafeína [Sección 2].\n",
    "\n",
    "A continuación, exploraremos tres métodos distintos para evaluar el dominio de aplicabilidad y los aplicaremos a la molécula de ejemplo:\n",
    "\n",
    "* Leverages [Sección 3],\n",
    "\n",
    "* Similitud Tanimoto-Jaccard [Sección 4],\n",
    "\n",
    "* Distancias euclidianas [Sección 5].\n",
    "\n",
    "Finalmente, aplicaremos el procedimiento completo a una lista de moléculas [Sección 6]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6df85b",
   "metadata": {
    "id": "bf6df85b"
   },
   "source": [
    "The third step is to prepare the files that we are going to use along the lesson. In this case, files will be requested later, but remember to upload them to be able to read. (Check previous lessons if need help to upload files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937afb1",
   "metadata": {
    "id": "6937afb1"
   },
   "source": [
    "## Sección 1: Preparación del modelo a usar para la predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFFRUgXl8CkY",
   "metadata": {
    "id": "oFFRUgXl8CkY"
   },
   "source": [
    "Para realizar una predicción QSAR, necesitamos tener un **modelo QSAR**.\n",
    "Por lo tanto, vamos a **recuperar nuevamente el modelo seleccionado**.\n",
    "Vamos a utilizar la misma función que empleamos en la lección anterior para **entrenar un modelo** a partir del nombre de los archivos de descriptores (entrenamiento y prueba) y del algoritmo configurado.\n",
    "\n",
    "Ejecuta la siguiente celda para **definir la función**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TUm9ElCU8g3I",
   "metadata": {
    "id": "TUm9ElCU8g3I"
   },
   "outputs": [],
   "source": [
    "#Importa las librerias necesarias\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "results={}\n",
    "def check_classification_model(model,train_file,test_file,name,save=True):\n",
    "\n",
    "    #Carga el dataset de entrenamiento y test y crea dataframes con los descriptores y la variable dependiente\n",
    "    train_dataset = pd.read_csv(train_file,sep=',')\n",
    "    X_train = train_dataset.iloc[:, 2:]\n",
    "    Y_train = train_dataset[\"y\"]\n",
    "\n",
    "    test_dataset = pd.read_csv(test_file,sep=',')\n",
    "    X_test = test_dataset.iloc[:, 2:]\n",
    "    Y_test = test_dataset[\"y\"]\n",
    "\n",
    "    #Ajusta el modelo (solo con el train)\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    #Predice el train y calcula las metricas\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    tr_Accuracy=round(accuracy_score(Y_train,Y_train_pred),2)\n",
    "    tr_Sensitivity=round(recall_score(Y_train,Y_train_pred),2)\n",
    "    tr_Specificity=round(recall_score(Y_train,Y_train_pred,pos_label=0),2)\n",
    "    tr_Precision=round(precision_score(Y_train,Y_train_pred),2)\n",
    "    tr_cm=confusion_matrix(Y_train,Y_train_pred)\n",
    "\n",
    "    #Predice el test y calcula las metricas\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "    ts_Accuracy=round(accuracy_score(Y_test,Y_test_pred),2)\n",
    "    ts_Sensitivity=round(recall_score(Y_test,Y_test_pred),2)\n",
    "    ts_Specificity=round(recall_score(Y_test,Y_test_pred,pos_label=0),2)\n",
    "    ts_Precision=round(precision_score(Y_test,Y_test_pred),2)\n",
    "    ts_cm=confusion_matrix(Y_test,Y_test_pred)\n",
    "\n",
    "    #Aplica la validacion cruzada y guarda solo la exactitud(accuracy) del test\n",
    "    cv_results = cross_validate(model, X_train, Y_train,scoring='accuracy',return_train_score=True)\n",
    "    cv_Accuracy_mean=round(cv_results['test_score'].mean(),3)\n",
    "    cv_Accuracy_dev=round(cv_results['test_score'].std(),3)\n",
    "\n",
    "    if save:\n",
    "      results.update({name:[tr_Accuracy,tr_Sensitivity,tr_Specificity,tr_Precision,\n",
    "            ts_Accuracy,ts_Sensitivity,ts_Specificity,ts_Precision,\n",
    "            cv_Accuracy_mean,cv_Accuracy_dev]})\n",
    "\n",
    "    #Muestra la matriz de confusion y las metricas calculadas\n",
    "    print('\\t\\tTRAIN\\t\\t\\t\\tTEST')\n",
    "    print('\\t\\tNeg.\\tPos.\\t\\t\\tNeg.\\tPos.')\n",
    "    print('\\tNegative\\t'+str(tr_cm[0][0])+'\\t'+str(tr_cm[0][1])+'\\t\\tNegative\\t'+str(ts_cm[0][0])+'\\t'+str(ts_cm[0][1]))\n",
    "    print('\\tPositive\\t'+str(tr_cm[1][0])+'\\t'+str(tr_cm[1][1])+'\\t\\tPositive\\t'+str(ts_cm[1][0])+'\\t'+str(ts_cm[1][1]))\n",
    "    print('Accuracy:\\t',tr_Accuracy,'\\t\\t\\t\\t',ts_Accuracy)\n",
    "    print('Sensitivity:\\t',tr_Sensitivity,'\\t\\t\\t\\t',ts_Sensitivity)\n",
    "    print('Specificity:\\t',tr_Specificity,'\\t\\t\\t\\t',ts_Specificity)\n",
    "    print('Precision:\\t',tr_Precision,'\\t\\t\\t\\t',ts_Precision)\n",
    "    print('Cross validation test accuracy:',cv_Accuracy_mean,'+/-',cv_Accuracy_dev)\n",
    "\n",
    "    return [tr_Accuracy,tr_Sensitivity,tr_Specificity,tr_Precision,\n",
    "            ts_Accuracy,ts_Sensitivity,ts_Specificity,ts_Precision,\n",
    "            cv_Accuracy_mean,cv_Accuracy_dev]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZIZJDe_o9T8i",
   "metadata": {
    "id": "ZIZJDe_o9T8i"
   },
   "source": [
    "Aplica la función al modelo que has seleccionado y realiza las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2vzHxOJR9eXo",
   "metadata": {
    "id": "2vzHxOJR9eXo"
   },
   "outputs": [],
   "source": [
    "#Importa el algoritmo seleccionado\n",
    "from ______________  \n",
    "\n",
    "#Inicializa el estimador con los hiperparametros seleccionados\n",
    "estimator = _______________  \n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           _________, \n",
    "                           ___________________,  \n",
    "                           'Selected_model')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "htIPOHOc7ZAa",
   "metadata": {
    "id": "htIPOHOc7ZAa"
   },
   "source": [
    "## Sección 2: Predicción de la actividad de la cafeína frente a lombrices de tierra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce7225",
   "metadata": {
    "id": "49ce7225"
   },
   "source": [
    "Comencemos con la cafeína. Tu primera tarea es obtener el SMILES de la cafeína.\n",
    "\n",
    "Una vez lo tengas, aplica el código en Python que aparece a continuación para visualizar la molécula a partir del SMILES utilizando RDKit (creando un objeto mol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_A58eqHwxOUI",
   "metadata": {
    "id": "_A58eqHwxOUI"
   },
   "outputs": [],
   "source": [
    "#Importa la Chem de RDKit\n",
    "\n",
    "\n",
    "#Asigna el SMILES de la molecula y obtén el objeto mol\n",
    "smiles= _________________  \n",
    "mol = _________________    \n",
    "\n",
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac0189",
   "metadata": {
    "id": "8fac0189"
   },
   "source": [
    "El siguiente paso es calcular los descriptores, retomando lo que hiciste en la parte 2.\n",
    "En este caso, no necesitas calcular todos los descriptores, sino solo aquellos que estás utilizando en tu modelo.\n",
    "Por lo tanto, calcular únicamente los descriptores necesarios es una alternativa más eficiente.\n",
    "\n",
    "Sin embargo, para simplificar el código en este punto, puedes reutilizar el código de la parte 2 para calcular todos los descriptores y guardarlos en un DataFrame.\n",
    "Los pasos para esto son:\n",
    "\n",
    "1. El código utilizado en la parte 2 emplea un DataFrame para introducir la lista de SMILES, así que debes crear un DataFrame con la columna \"SMILES\".\n",
    "\n",
    "1. Calcular los descriptores de RDKit e incluirlos en el mismo DataFrame.\n",
    "\n",
    "1. Calcular los descriptores de Mordred en un DataFrame diferente y concatenarlo al anterior.\n",
    "\n",
    "1. Seleccionar únicamente las columnas correspondientes a los descriptores seleccionados y guardarlas en un DataFrame diferente (llámalo X_caf).\n",
    "\n",
    "Finalmente, deberías obtener un DataFrame X_caf con las columnas de solo los descriptores (puedes obtener los nombres de X_train o X_test).\n",
    "Ten en cuenta que el orden de las columnas es importante, ya que el código que genera y utiliza el modelo no leerá los nombres, sino que asumirá que están en el mismo orden.\n",
    "\n",
    "Notas:\n",
    "\n",
    "* Evita usar \"descriptors\" como nombre de variable porque sobrescribirá la lista importada de descriptores de Mordred.\n",
    "\n",
    "* Puedes utilizar directamente la columna 'SMILES' como lista de SMILES o guardarla como lista aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ec2b5",
   "metadata": {
    "id": "b24ec2b5"
   },
   "outputs": [],
   "source": [
    "#Importa los módulos y funciones necesarios (pandas, mordred y rdkit)\n",
    "\n",
    "\n",
    "\n",
    "#Crea un dataframe con una sola columna que se llama SMILES e incluye una lista con los SMILES\n",
    "df_caf=___________\n",
    "\n",
    "\n",
    "#Calcula los descriptores de RDKit\n",
    "\n",
    "\n",
    "#Concatena los resultados a df_caf (los SMILES) en un nuevo dataframe df_caf_desc\n",
    "df_caf_desc = pd.concat(________________________)\n",
    "\n",
    "\n",
    "#Calcula los descriptores de Mordred\n",
    "\n",
    "\n",
    "\n",
    "#Concatena los resultados a df_caf_desc en un nuevo dataframe df_caf_desc2\n",
    "df_caf_desc2 =\n",
    "\n",
    "\n",
    "#Muestra el tamaño del dataframe para asegurarte de que todos los descriptores están incluidos\n",
    "print(\"\\nShape of the final df:\",df_caf_desc.shape)\n",
    "\n",
    "\n",
    "#Carga el dataset de entrenamiento o de validación para obtener el nombre de los descriptores\n",
    "train_database = pd.read_csv(___________)\n",
    "\n",
    "\n",
    "#La lista de descriptores debe ser todas las columnas excepto las dos primeras\n",
    "descs =_______________\n",
    "\n",
    "X_caf = df_calc_df2[descs]\n",
    "\n",
    "\n",
    "#Visualiza los descriptores calculados\n",
    "X_caf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85092c14",
   "metadata": {
    "id": "85092c14"
   },
   "source": [
    "Revisa los valores de los descriptores obtenidos para tu molécula objetivo en el DataFrame anterior.\n",
    "En algunos casos, el cálculo de descriptores puede proporcionar valores no numéricos que no son útiles (como errores de cálculo o falta de parámetros para ciertos elementos).\n",
    "(Si ves valores como `True` y `False`, no son un problema, ya que se trata de variables binarias que el modelo interpreta como 1 y 0).\n",
    "\n",
    "No vamos a tener esto en cuenta aquí por simplicidad, pero la presencia de valores no numéricos, especialmente si representan un porcentaje significativo, es una señal de mala calidad en la predicción y puede implicar que no se pueda usar esa molécula en el modelo.\n",
    "Como hicimos con el conjunto completo, este problema se puede evitar utilizando un imputador kNN, que emplea el promedio de los valores de unas pocas moléculas vecinas del conjunto de datos original.\n",
    "\n",
    "De hecho, dado que entrenamos el modelo con una versión imputada y estandarizada de los descriptores,\n",
    "debemos seguir el mismo procedimiento en lugar de usar los descriptores sin procesar.\n",
    "Por tanto, para poder calcular una predicción, necesitamos comprobar los descriptores de la molécula de predicción, rellenar los huecos y estandarizarlos usando el mismo método.\n",
    "\n",
    "Para comenzar este proceso, necesitamos recuperar los valores originales (sin procesar) de los descriptores obtenidos para el conjunto de entrenamiento (que fueron guardados en un archivo CSV después de la división).\n",
    "Abre en un DataFrame el CSV con los descriptores obtenidos antes de la imputación y estandarización del archivo de entrenamiento, y filtra las columnas correspondientes a los descriptores seleccionados para el modelo que vamos a usar.\n",
    "Llámalo `database_reduced`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb3e89",
   "metadata": {
    "id": "7ceb3e89"
   },
   "outputs": [],
   "source": [
    "#Obtén los valores preprocesados para entrenar el imputer/scaler\n",
    "train_database_noscaled = ______________________\n",
    "\n",
    "\n",
    "database_reduced = train_database_noscaled[____________]\n",
    "\n",
    " \n",
    "print(database_reduced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb58379",
   "metadata": {
    "id": "9fb58379"
   },
   "source": [
    "Además, necesitamos repetir la **estandarización** de los descriptores con el conjunto de datos original, como hicimos anteriormente.\n",
    "Pero en este caso, debemos **restringir el escalado a los descriptores que vamos a reescalar** (usando el DataFrame `database_reduced`).\n",
    "\n",
    "En la siguiente celda puedes utilizar la función imputer_scaler (similar a la definida previamente en la lección 2.5)\n",
    "para realizar la **imputación y el escalado** de una o más moléculas objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lB68CoQNRDAo",
   "metadata": {
    "id": "lB68CoQNRDAo"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def imputer_scaler(df_target, df_reference):\n",
    "    imputer = KNNImputer(missing_values=np.nan, n_neighbors=3, weights=\"uniform\")\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    columns_descriptors = list(df_reference.columns)\n",
    "\n",
    "    reference_descriptors_matrix = df_reference[columns_descriptors]\n",
    "\n",
    "    imputer.fit(reference_descriptors_matrix)\n",
    "\n",
    "    target_descriptors_matrix = df_target[columns_descriptors]\n",
    "\n",
    "    imputed_ref_matrix = imputer.transform(reference_descriptors_matrix)\n",
    "    imputed_matrix = imputer.transform(target_descriptors_matrix)\n",
    "    scaler.fit(imputed_ref_matrix)\n",
    "\n",
    "    imputed_scaled_matrix = scaler.transform(imputed_matrix)\n",
    "    df_imputed_scaled = pd.DataFrame(imputed_scaled_matrix, columns = columns_descriptors)\n",
    "\n",
    "    return df_imputed_scaled\n",
    "\n",
    "#Completa con las matrices de descriptores requeridas\n",
    "X_caf_scaled = imputer_scaler(_______________)\n",
    "\n",
    "X_caf_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22730a2e",
   "metadata": {
    "id": "22730a2e"
   },
   "source": [
    "Después de ejecutar tu código para ajustar y comprobar el modelo, realizar una predicción se hace de la misma manera que cuando evaluamos el entrenamiento y el test.\n",
    "\n",
    "Ten en cuenta que el resultado será una **lista con todas las predicciones**, incluso si solo se ha hecho una.\n",
    "¿Cuál es la **predicción para la cafeína**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb2e15",
   "metadata": {
    "id": "bffb2e15"
   },
   "outputs": [],
   "source": [
    "#Predice la toxicidad de la cafeina con el modelo entrenado\n",
    "Y_caf_pred =   _______\n",
    "\n",
    "\n",
    "#Muestra los resultados de la predicción\n",
    "Y_caf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IJHm6kGwlplD",
   "metadata": {
    "id": "IJHm6kGwlplD"
   },
   "source": [
    "### **Q1.** ¿Cuál es la toxicidad predicha para la cafeina?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9HpNZC8VlukC",
   "metadata": {
    "id": "9HpNZC8VlukC"
   },
   "source": [
    "¿Cómo de seguros estamos de esta predicción?\n",
    "Un primer enfoque es comprobar la probabilidad asignada por el propio algoritmo de aprendizaje automático.\n",
    "Utiliza el método `predict_proba` para obtener la probabilidad de que sea negativa (primer valor) y positiva (segundo valor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdyQIZ_slmJk",
   "metadata": {
    "id": "fdyQIZ_slmJk"
   },
   "outputs": [],
   "source": [
    "#Obtén la probabilidad de que la cafeina sea positiva para la toxicidad\n",
    "Y_caf_prob = ____________\n",
    "\n",
    "\n",
    "#Muestra la probabilidad\n",
    "Y_caf_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nxi58vHyvntZ",
   "metadata": {
    "id": "Nxi58vHyvntZ"
   },
   "source": [
    "**Nota:** Si has seleccionado una máquina de vectores de soporte (SVM) como algoritmo, esto no es posible por defecto.\n",
    "Existe una forma de habilitar el cálculo de probabilidades (que debe activarse durante el ajuste del modelo), pero no es necesario para continuar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e86ec",
   "metadata": {
    "id": "432e86ec"
   },
   "source": [
    "## Dominio de Aplicabilidad de la Cafeína en el Modelo de Lombrices de Tierra\n",
    "\n",
    "Se ha realizado una predicción, pero ¿podemos confiar en ella?\n",
    "Además de evaluar la calidad general del modelo, necesitamos comprobar si la molécula que estamos analizando se encuentra dentro del espacio químico considerado por nuestro modelo.\n",
    "Para ello, medimos el dominio de aplicabilidad.\n",
    "\n",
    "Existen varios métodos para hacerlo, como:\n",
    "\n",
    "* Leverage\n",
    "\n",
    "* Distancia euclidiana\n",
    "\n",
    "* Similitud de Tanimoto\n",
    "\n",
    "* Estimación de Densidad por Núcleo (Kernel Density Estimation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5FzBfBOf0Hvz",
   "metadata": {
    "id": "5FzBfBOf0Hvz"
   },
   "source": [
    "## Sección 3: Índice de Tanimoto\n",
    "\n",
    "El índice de Tanimoto es una medida de similitud molecular basada en las huellas moleculares (fingerprints).\n",
    "Por lo tanto, lo primero que necesitamos es obtener una huella molecular.\n",
    "Una fingerprint es un identificador formado por una cadena binaria que indica la presencia o ausencia de determinados grupos o características en una molécula.\n",
    "\n",
    "No existe un único conjunto de características, por lo que hay varios tipos de fingerprints disponibles.\n",
    "En este caso, vamos a utilizar la huella MACCS Keys.\n",
    "\n",
    "Se puede calcular utilizando el módulo rdMolDescriptors de RDKit\n",
    "(consulta la documentación aquí: https://www.rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html).\n",
    "\n",
    "Obtén la huella MACCS de la cafeína.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea4bf5",
   "metadata": {
    "id": "6aea4bf5"
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "#Obténe el fingerprint de la cafeina usando el objeto mol creado antes\n",
    "fingerprint = __________________\n",
    "\n",
    "\n",
    "# Keep the prints to check your work\n",
    "print(\"Fingerprint should be an ExplicitBitVect object:\",fingerprint)\n",
    "print(\"This object can be expanded to a list of 0/1 values:\",list(fingerprint))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3eecf",
   "metadata": {
    "id": "2cb3eecf"
   },
   "source": [
    "Como puedes ver, la huella molecular (fingerprint) es un objeto binario por motivos de eficiencia, pero se puede convertir en una lista para comprobar individualmente los valores 0 y 1.\n",
    "\n",
    "Ahora necesitamos comparar esta fingerprint con las del conjunto de entrenamiento. Vamos a utilizar el coeficiente de similitud de Jaccard-Tanimoto, que se calcula como:\n",
    "\n",
    "$$S_{J-T} = \\frac{P_{both}}{P_{both}+P_{1}+P_{2}} $$\n",
    "donde P representa el número de características que son positivas en ambas moléculas, solo en la primera y solo en la segunda (${P_{both}}$, $P_{1}$, y $P_{2}$, respectivamente).\n",
    "\n",
    "Como prueba, vamos a calcular el índice de similitud de la cafeína con el ácido butírico y la nicotina, utilizando la fórmula mencionada anteriormente.\n",
    "Ten en cuenta que la forma más sencilla de operar con los 0s y 1s del índice es convertirlo a una lista previamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czluw_btmHwz",
   "metadata": {
    "id": "czluw_btmHwz"
   },
   "outputs": [],
   "source": [
    "but_smiles=  Chem.MolFromSmiles(\"O=C(O)CCC\")\n",
    "butiric = rdMolDescriptors.GetMACCSKeysFingerprint(but_smiles)\n",
    "nico_smiles = ___________\n",
    "nicotine = ____________\n",
    "lbutiric = list(butiric)\n",
    "lnicotine = list(nicotine)\n",
    "lfingerprint = list(fingerprint)\n",
    "\n",
    "p_both = 0\n",
    "p_1 = 0\n",
    "p_2 = 0\n",
    "for i,j in enumerate(fingerprint):\n",
    "    if  lfingerprint[i]==__  and lnicotine[i]==__:\n",
    "        p_both = p_both+1\n",
    "    elif lfingerprint[i]==__ and lnicotine[i]==__:\n",
    "        p_1 = p_1+1\n",
    "    elif lfingerprint[i]==__ and lnicotine[i]==__:\n",
    "        p_2 = p_2+1\n",
    "\n",
    "sim_nico = p_both / (p_both+p_1+p_2)\n",
    "p_both = 0\n",
    "p_1 = 0\n",
    "p_2 = 0\n",
    "for i,j in enumerate(fingerprint):\n",
    "    if  lfingerprint[i]==__ and lbutiric[i]==__:\n",
    "        p_both = p_both+1\n",
    "    elif lfingerprint[i]==__ and lbutiric[i]==__:\n",
    "        p_1 = p_1+1\n",
    "    elif lfingerprint[i]==__ and lbutiric[i]==__:\n",
    "        p_2 = p_2+1\n",
    "\n",
    "sim_buti = p_both / (p_both+p_1+p_2)\n",
    "\n",
    "# Keep the prints to check your work\n",
    "print(\"Fingerprint of caffeine:\",list(fingerprint))\n",
    "print(\"Fingerprint of nicotine:\",list(nicotine))\n",
    "print(\"Fingerprint of butiric acid:\",list(butiric))\n",
    "print(\"Similarity index for nicotine (should be 0.386):\",round(sim_nico,3))\n",
    "print(\"Similarity index for butiric acid (should be 0.070):\",round(sim_buti,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a84b3",
   "metadata": {
    "id": "e62a84b3"
   },
   "source": [
    "Por otro lado, RDKit tiene una función llamada `FingerprintSimilarity` que calcula directamente el índice de similitud a partir del vector binario.\n",
    "Utiliza esta función y comprueba que devuelve los mismos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc6665",
   "metadata": {
    "id": "c5dc6665"
   },
   "outputs": [],
   "source": [
    "from rdkit import DataStructs\n",
    "\n",
    "sim_nico = DataStructs.FingerprintSimilarity(fingerprint,nicotine)\n",
    "sim_buti = DataStructs.FingerprintSimilarity(fingerprint,butiric)\n",
    "\n",
    "print(\"Similarity index for nicotine (should be 0.386):\",round(sim_nico,3))\n",
    "print(\"Similarity index for butiric acid (should be 0.070):\",round(sim_buti,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05ba11",
   "metadata": {
    "id": "ea05ba11"
   },
   "source": [
    "Para aplicar esto y comprobar el espacio químico de una base de datos, necesitamos calcular el índice de similitud de nuestra molécula objetivo con cada molécula del conjunto de entrenamiento.\n",
    "Para cada una de ellas, obtendremos su fingerprint y calcularemos el índice.\n",
    "\n",
    "Finalmente, para que la cafeína esté dentro del dominio de aplicabilidad, debe ser similar al menos a una de nuestras moléculas.\n",
    "Por tanto, solo necesitamos centrarnos en la más similar (el valor más alto).\n",
    "\n",
    "Así que no es necesario almacenar todos los valores, sino únicamente mantener el valor máximo y mostrarlo al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f5b27",
   "metadata": {
    "id": "5c9f5b27"
   },
   "outputs": [],
   "source": [
    "#Importa los módulos necesarios\n",
    "\n",
    "\n",
    "#Para evitar errores, mejor incluye de nuevo el SMILES de la cafeina y vuelve a obtener el objeto mol\n",
    "smiles=__________________\n",
    "mol =__________\n",
    "target_fingerprint = ____________________\n",
    "\n",
    "\n",
    "#Usa la columna SMILES del dataframe train_database abierto antes\n",
    "smi_train = train_database['SMILES']\n",
    "\n",
    "#Define la variable para guardar el maximo y asignale un valor bajo (0.0)\n",
    "max_sim = 0.00\n",
    "#Itera sobre los SMILES del dataset de entrenamiento\n",
    "for i in ____________________\n",
    "    #Obtén el objeto mol y el fingerprint\n",
    "\n",
    "    train_fingerprint =  ___________________\n",
    "\n",
    "    #Calcula el score (con la funcion FingerprintSimilarity)\n",
    "    sim_score = rdkit.DataStructs.FingerprintSimilarity(_______________)\n",
    "    #Actualiza el valor si el nuevo es mayor\n",
    "    if sim_score > max_sim:\n",
    "        max_sim = sim_score\n",
    "\n",
    "print('Maximum similarity index:',round(max_sim,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ab1de",
   "metadata": {
    "id": "f12ab1de"
   },
   "source": [
    "El valor de similitud considerado como incluido en el dominio de aplicabilidad depende del tipo de fingerprint utilizado.\n",
    "Por ejemplo, para las huellas MACCS, un valor aceptable es 0.573, lo que corresponde a una similitud superior al 95 %.\n",
    "\n",
    "Puedes encontrar más información en: http://rdkit.blogspot.com/2013/10/fingerprint-thresholds.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gAJqv_qoAHtq",
   "metadata": {
    "id": "gAJqv_qoAHtq"
   },
   "source": [
    "### **Q2.** ¿Cuál es el valor máximo del índice de similitud de Tanimoto-Jaccard para la cafeína en tu conjunto de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bNGqz5fj4WzB",
   "metadata": {
    "id": "bNGqz5fj4WzB"
   },
   "source": [
    "## Sección 4: Leverage\n",
    "\n",
    "En estadística, el leverage es una medida estadística de cuán diferente es cada compuesto respecto al grupo, basándose en los valores de los descriptores.\n",
    "A continuación encontrarás una función con el cálculo de esta medida, que es matemáticamente algo compleja y no vamos a analizar en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bx8UXQuw4WzC",
   "metadata": {
    "id": "Bx8UXQuw4WzC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def leverage(X_train,X_target):\n",
    "        X_train = X_train.astype(float)\n",
    "\n",
    "\n",
    "        tranpX = np.transpose(X_train)\n",
    "        xtx = np.dot(tranpX, X_train)\n",
    "        invxtx = np.linalg.inv(xtx)\n",
    "\n",
    "\n",
    "        leverages_target = []\n",
    "\n",
    "        for idx, row in X_target.iterrows():\n",
    "            transposed_row = np.transpose(row)\n",
    "            leverage = np.dot(np.dot(row, invxtx), transposed_row)\n",
    "            leverages_target.append(leverage.round(4))\n",
    "\n",
    "        return leverages_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a-BEVBIs4WzC",
   "metadata": {
    "id": "a-BEVBIs4WzC"
   },
   "source": [
    "Además de las diferencias estructurales, los valores de leverage dependen en gran medida del número de moléculas incluidas en el conjunto de entrenamiento y del número de descriptores.\n",
    "Por lo tanto, el valor utilizado para evaluar si una molécula es lo suficientemente similar como para estar incluida en el dominio de aplicabilidad depende de esos dos factores, y se calcula como: 3 × (número de descriptores / número de moléculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72mtgIBCx7H3",
   "metadata": {
    "id": "72mtgIBCx7H3"
   },
   "outputs": [],
   "source": [
    "#Crea un DataFrame con los descriptores de la base de datos de entrenamiento\n",
    "X_train_scaled=  _____________________\n",
    "\n",
    "#Calcula el límite de leverage\n",
    "p = X_train_scaled._______  #número de descriptores\n",
    "n = X_train_scaled.__________  #número de moléculas\n",
    "warning_leverage = 3*(p/n)\n",
    "\n",
    "leverages = leverage(X_train_scaled,X_caf_scaled)\n",
    "\n",
    "leverages_in_out = []\n",
    "for value in leverages:\n",
    "    if value < warning_leverage:\n",
    "            leverages_in_out.append('IN')\n",
    "    else:\n",
    "            leverages_in_out.append('OUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b40f98",
   "metadata": {
    "id": "e6b40f98"
   },
   "source": [
    "## Sección5: Distacnia Euclideana\n",
    "\n",
    "Otra medida de similitud entre moléculas que puede utilizarse para evaluar el dominio de aplicabilidad es la distancia euclidiana. La distancia euclidiana es la medida de distancia comúnmente utilizada en geometría, pero en este caso se extiende a N dimensiones, donde cada dimensión representa uno de los descriptores utilizados en el modelo. La fórmula es\n",
    "\n",
    "$d(p,q) = \\sqrt{(p_1+q_1)^2+(p_2+q_2)^2+...+(p_n+q_n)^2} $, para n dimensiones, donde $p_i$ y $q_i$ son los valores estandarizados del descriptor i para cada molécula.\n",
    "\n",
    "Como la magnitud de las distancias euclidianas depende de los descriptores, no existe un valor de referencia fijo.\n",
    "Por ello, necesitamos comparar la distancia de nuestra molécula con el espacio químico en función de las distancias entre las moléculas del conjunto de entrenamiento.\n",
    "\n",
    "Podemos escribir código para calcular esta distancia y recorrer el conjunto de entrenamiento, como hicimos con la similitud de Tanimoto,\n",
    "pero en este caso vamos a aprovechar una función de sklearn que calcula directamente la distancia euclidiana por pares para todo el conjunto de datos:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html\n",
    "\n",
    "En primer lugar, calculamos la distancia euclidiana entre X_train y sí mismo.\n",
    "\n",
    "Esta función proporciona todos los valores de la matriz de distancias por pares como una lista de listas, ya que permite calcular distancias para más de una predicción al mismo tiempo.\n",
    "Como con Tanimoto, no necesitamos todos los valores, sino uno solo que nos sirva para justificar si nuestra molécula está dentro del dominio de aplicabilidad.\n",
    "En este caso, nos interesa la máxima distancia entre moléculas del conjunto de entrenamiento.\n",
    "\n",
    "Pista:\n",
    "Una forma sencilla de calcular el valor máximo de la matriz (lista de listas) es aplanarla a una sola lista usando el método flatten: `list_of_lists.flatten()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35739e6",
   "metadata": {
    "id": "b35739e6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "tr_distances = euclidean_distances(X_train_scaled,X_train_scaled)\n",
    "\n",
    "\n",
    "max_ed= max(tr_distances.flatten())\n",
    "\n",
    "print('The maximum value of the Eucledian distance in the training set is ', max_ed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c18090",
   "metadata": {
    "id": "09c18090"
   },
   "source": [
    "El siguiente paso es calcular la distancia euclidiana máxima entre nuestra molécula objetivo, la cafeína, y el conjunto de entrenamiento,\n",
    "utilizando la misma función (`euclidean_distances`).\n",
    "Si esta distancia es menor que la máxima distancia entre moléculas del conjunto de entrenamiento, entonces nuestra molécula está dentro del dominio de aplicabilidad.\n",
    "\n",
    "Incluye en tu código no solo el cálculo de la distancia euclidiana máxima,\n",
    "sino también una variable llamada `AD_eucledian` con valor `YES` o `NO` dependiendo del resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70003ae",
   "metadata": {
    "id": "b70003ae"
   },
   "outputs": [],
   "source": [
    "#Importa los módulos necesarios\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "#Las distancias se calculan de la misma manera, pero combinando los dataframes de objetivo y entrenamiento\n",
    "caf_distances = _______________________\n",
    "\n",
    "max_ed_caf= _________________________\n",
    "\n",
    "if max_ed_caf <= max_ed:\n",
    "    AD_eucledian = _________ #Asigna IN o OUT\n",
    "else:\n",
    "    AD_eucledian = __________ #Asigna IN o OUT\n",
    "\n",
    "print('The maximum value of the Eucledian distance between caffeine and the training set is ', max_ed_caf)\n",
    "print('Is caffeine in the applicability domain of your model?',AD_eucledian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d5699",
   "metadata": {
    "id": "a46d5699"
   },
   "source": [
    "## Sección 6: Ejercicio con multiples moléculas\n",
    "\n",
    "Predice la toxicidad de las siguientes moléculas utilizando el modelo de toxicidad aguda en lombrices de tierra e incluye si están dentro del dominio de aplicabilidad, según el índice de Jaccard-Tanimoto:\n",
    "\n",
    "* Nombre: Fenol\n",
    "\n",
    "* CAS: 50-78-2\n",
    "\n",
    "* SMILES: COCO\n",
    "\n",
    "* Nombre: Nicotina\n",
    "\n",
    "* Nombre: Estreptoquinasa\n",
    "\n",
    "* CAS: 9002-01-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hFSbD0TSL7A5",
   "metadata": {
    "id": "hFSbD0TSL7A5"
   },
   "source": [
    " ### Paso 1: Genera un DataFrame con una única columna llamada 'SMILES' y complétalo con los SMILES de tus moléculas objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4104d",
   "metadata": {
    "id": "b2f4104d"
   },
   "outputs": [],
   "source": [
    "#ESCRIBE AQUÍ TU CÓDIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b91f2",
   "metadata": {
    "id": "ae6b91f2"
   },
   "source": [
    "### Paso 2: Comprueba el modelo:\n",
    "* Regenera el modelo\n",
    "\n",
    "* Recupera X_train con los descriptores sin escalar del conjunto de entrenamiento\n",
    "\n",
    "* Recupera la lista de descriptores seleccionados como `sel_descriptors`\n",
    "\n",
    "(Esto realmente no es necesario si ya tienes las variables de secciones anteriores, pero es recomendable repetirlo para asegurarse de que estamos accediendo al modelo correcto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761acc5",
   "metadata": {
    "id": "f761acc5"
   },
   "outputs": [],
   "source": [
    "estimator = ___________________________\n",
    "metrics = check_classification_model(estimator,\n",
    "                           ,\n",
    "                           ,\n",
    "                           'Final')\n",
    "\n",
    "train_database = pd.read_csv(______________)  #Conjunto de entrenamiento no escalado\n",
    "\n",
    "descriptors_df = pd.read_csv(_____________) # Descriptores seleccionados\n",
    "sel_descriptors =_____________\n",
    "\n",
    "#Reduce el juego de datos de entrenamiento a los descriptores seleccionados\n",
    "train_database = train_database[sel_descriptors]\n",
    "train_database_scaled = descriptors_df[sel_descriptors]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94e65a",
   "metadata": {
    "id": "5b94e65a"
   },
   "source": [
    "### Paso 3: Calcula y procesa los descriptores seleccionados para todos los compuestos objetivo.\n",
    "\n",
    "Revisa y adapta el código de la Sección 2.\n",
    "En este caso, los SMILES deben leerse desde df_target y los descriptores seleccionados provienen de la celda anterior.\n",
    "Puedes dividir el código en varias celdas si lo prefieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c742b14",
   "metadata": {
    "id": "7c742b14"
   },
   "outputs": [],
   "source": [
    "#Calcula los descriptores de RDKIT\n",
    "\n",
    "\n",
    "#Calcula los descriptores de Mordred\n",
    "\n",
    "\n",
    "#Combina los dos dataframes en uno nuevo\n",
    "df_target_desc=_______\n",
    "\n",
    "\n",
    "#Muestra el tamaño del dataframe para asegurarte de que todos los descriptores están incluidos\n",
    "print(\"\\nShape of the final df:\",df_target_desc.shape)\n",
    "\n",
    "#Reduce el dataframe a los descriptores seleccionados\n",
    "X_target = df_target_desc[sel_descriptors]\n",
    "\n",
    "#Ejecuta la función imputer_scaler para obtener los descriptores escalados\n",
    "X_target_scaled = imputer_scaler___________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X_target)\n",
    "print(X_target_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f033240",
   "metadata": {
    "id": "7f033240"
   },
   "source": [
    "### Paso 4: Lleva a cabo las predicciones y guárdalas como una lista.\n",
    "\n",
    "Recuerda que el método `predict` lee una tabla completa, por lo que puedes hacer todas las predicciones a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e29e8f",
   "metadata": {
    "id": "42e29e8f"
   },
   "outputs": [],
   "source": [
    "#ESCRIBE AQUÍ TU CÓDIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29eb25",
   "metadata": {
    "id": "db29eb25"
   },
   "source": [
    "### Paso 5: Calcula el dominio de aplicabilidad.\n",
    "\n",
    "  Aplica **el índice de Jaccard-Tanimoto** y obtén una **lista con valores 'YES'/'NO'** que indiquen si cada molécula está dentro del **dominio de aplicabilidad** (AD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c22198",
   "metadata": {},
   "source": [
    " * Índice de Jaccard-Tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab04af4",
   "metadata": {
    "id": "1ab04af4"
   },
   "outputs": [],
   "source": [
    "#@title Use tanimoto\n",
    "threshold = 0.573\n",
    "\n",
    "\n",
    "#Obtén la lista de SMILES de los datasets\n",
    "smi_train = descriptors_df['SMILES']\n",
    "smi_target = _____\n",
    "\n",
    "\n",
    "AD_tanimoto=[]\n",
    "for smi in smi_target:\n",
    "    target_fingerprint = ________\n",
    "\n",
    "    for i in smi_train:\n",
    "        train_fingerprint = _____\n",
    "        sim_score = ______\n",
    "        #Comprueba si el score es obtenido es el mayor\n",
    "\n",
    "\n",
    "    #Muestra la mayor similitud obtenida\n",
    "    print('Maximum similarity index:',round(max_sim,3))\n",
    "    #Comáralo con el umbral para añadir YES o NO a la lista\n",
    "\n",
    "#Muestra la lista de resultados\n",
    "AD_tanimoto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098b2a5",
   "metadata": {
    "id": "2098b2a5"
   },
   "source": [
    "Presenta tus resultados como un DataFrame con las columnas \"SMILES\", \"Prediction\", \"Tanimoto\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d19d28",
   "metadata": {
    "id": "c9d19d28",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dataframe = pd.DataFrame(df_target['SMILES'],columns=['SMILES'])\n",
    "final_dataframe['Prediction'] = ____\n",
    "final_dataframe['Tanimoto'] = ______\n",
    "\n",
    "\n",
    "final_dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oaf8Ig850dqfp2VVyhn4YucQ4wYAOM7i",
     "timestamp": 1684842248158
    },
    {
     "file_id": "https://github.com/mpalominoschaetzlein/Python_QSAR_course/blob/main/Module2_QSAR_model_1_Classification.ipynb",
     "timestamp": 1683798218234
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

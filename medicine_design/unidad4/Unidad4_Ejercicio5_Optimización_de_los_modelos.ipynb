{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59b2543",
   "metadata": {
    "id": "a59b2543"
   },
   "source": [
    "# Módulo 4: Modelo de clasificación QSAR (paso a paso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f496f",
   "metadata": {
    "id": "cf6f496f"
   },
   "source": [
    "En este módulo desarrollaremos nuestro primer modelo QSAR, concretamente un modelo para la toxicidad aguda en lombrices de tierra. Dado que desarrollar un modelo QSAR implica un flujo de trabajo con varios pasos y este es tu primer modelo, este módulo será extenso, ya que exploraremos cada paso cuidadosamente. Por ello, el flujo de trabajo se divide en diferentes lecciones, y la práctica en Python correspondiente está separada en distintos archivos Jupyter Notebook. Como recordatorio, en este curso el flujo de trabajo para desarrollar un modelo QSAR se divide en las siguientes partes:\n",
    "\n",
    "- Parte 1: Obtención y depuración de datos\n",
    "- Parte 2: Cálculo de descriptores moleculares\n",
    "- Parte 3: División entre entrenamiento y prueba, y estandarización\n",
    "- Parte 4: Selección de descriptores\n",
    "- Parte 5: Desarrollo y optimización del modelo\n",
    "- Parte 6: Predicción y dominio de aplicabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4756a",
   "metadata": {
    "id": "18f4756a"
   },
   "source": [
    "\n",
    "# Parte 5: Desarrollo y optimización del modelo\n",
    "\n",
    "En esta lección finalizaremos el desarrollo de un modelo predictivo de aprendizaje automático entrenando diferentes versiones y seleccionando la mejor.\n",
    "\n",
    "Primero, entrenaremos un modelo de aprendizaje automático en detalle [Sección 1] y veremos cómo evaluar su calidad [Sección 2].\n",
    "\n",
    "A continuación, evaluaremos cómo distintos cambios pueden aplicarse para modificar el rendimiento del modelo [Sección 3].\n",
    "\n",
    "Finalmente, compararemos las métricas de los modelos y seleccionaremos el mejor modelo QSAR [Sección 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590007b",
   "metadata": {
    "id": "f590007b"
   },
   "source": [
    "## Sección 1: Ajustando un estimador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567feae0",
   "metadata": {
    "id": "567feae0"
   },
   "source": [
    "Como se vio en la sesión teórica, un modelo QSAR es un algoritmo de aprendizaje automático que se entrena a partir de un conjunto de datos experimentales (moléculas definidas por un conjunto de descriptores y con un valor objetivo conocido), de modo que es capaz de modelar el sistema y predecir la propiedad.\n",
    "Por lo tanto, el primer paso es preparar los datos necesarios para entrenar tu modelo: la matriz de descriptores y los valores objetivo.\n",
    "\n",
    "Recuerda que dividimos nuestros datos en dos conjuntos: **entrenamiento** y **prueba**. Así que ahora utilizaremos únicamente el conjunto de entrenamiento.\n",
    "Además, debemos proporcionar al modelo un conjunto adecuado de características, por lo que obtendremos los datos a partir de los resultados del método de selección de características y los almacenaremos como un DataFrame de pandas.\n",
    "En particular, vamos a utilizar las características seleccionadas mediante RFE con el estimador de Regresión Logística.\n",
    "Deberías haber guardado este conjunto como un archivo CSV (con el nombre \"Earthworm_acute_toxicity_Train_RFE_logreg.csv\" o similar) en el ejercicio anterior.\n",
    "\n",
    "Una vez abierto el archivo, deberías obtener dos matrices distintas para ajustar tu modelo:\n",
    "\n",
    "* La matriz de descriptores del conjunto de entrenamiento (X_train), formada solo por los descriptores,\n",
    "\n",
    "* La matriz de valores objetivo (Y_train), formada por los valores experimentales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_NFv4BdTPBQf",
   "metadata": {
    "id": "_NFv4BdTPBQf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dataset = _________\n",
    "\n",
    "X_train = ____________\n",
    "Y_train = ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489105b",
   "metadata": {
    "id": "d489105b"
   },
   "source": [
    "Puedes confirmar que los DataFrames X_train y Y_train son correctos mostrando las columnas de X_train (deberían ser los descriptores seleccionados para el modelo) y los tamaños de ambas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811996b",
   "metadata": {
    "id": "e811996b"
   },
   "outputs": [],
   "source": [
    "print(\"The columns of X_train are :\", _____________________)\n",
    "print(\"The number of rows in X_train is:\", ___________________)\n",
    "print(\"The number of columns in X_train is:\", _____________)\n",
    "print(\"The number of rows in Y_train is:\", ________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4500c0",
   "metadata": {
    "id": "9b4500c0"
   },
   "source": [
    "La segunda parte del proceso consiste en crear y ajustar el algoritmo de aprendizaje automático (también conocido como estimador).\n",
    "\n",
    "En general, esto dependerá mucho de qué implementación del algoritmo estés utilizando. En este curso, vamos a utilizar estimadores de scikit-learn, que se emplean de una forma muy similar.\n",
    "El primer paso es importar los módulos adecuados desde los paquetes de sklearn. Para el primer ejemplo, debes usar el algoritmo de Regresión Logística, que se llama `LogisticRegression` y se encuentra en el módulo `sklearn.linear_model`.\n",
    "\n",
    "Una vez seleccionado un algoritmo, el estimador debe inicializarse.\n",
    "El estimador es el objeto de Python que contiene y aplica el algoritmo de aprendizaje automático.\n",
    "En este caso, crearemos el objeto estimador y lo llamaremos model, simplemente llamando a la función que hemos importado anteriormente.\n",
    "\n",
    "En este paso no solo decidimos qué estimador/algoritmo vamos a usar, sino que también podemos incluir parámetros para ajustar su comportamiento.\n",
    "Estos parámetros son los que normalmente llamamos hiperparámetros.\n",
    "Por ejemplo, en el caso de abajo, se asigna un valor de 5 al hiperparámetro 'C', que representa el inverso de la fuerza de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ed8a2",
   "metadata": {
    "id": "4f3ed8a2"
   },
   "outputs": [],
   "source": [
    "#Importa la función de regresión logística de SciKit-Learn\n",
    "\n",
    "#Initializa el objeto estimador de regresión logística\n",
    "model = ____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8db5a3",
   "metadata": {
    "id": "7a8db5a3"
   },
   "source": [
    "La última parte consiste en entrenar el modelo utilizando los datos obtenidos anteriormente.\n",
    "En los estimadores de scikit-learn, esto se realiza con el método `fit`, que requiere dos entradas: los datos de entrenamiento y los valores objetivo.\n",
    "Consulta cómo se utiliza en la documentación oficial:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N1eYWRwDbHKn",
   "metadata": {
    "id": "N1eYWRwDbHKn"
   },
   "outputs": [],
   "source": [
    "#ESCRIBE TU CÓDIGO AQUÍ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WBXIaSKstiIA",
   "metadata": {
    "id": "WBXIaSKstiIA"
   },
   "source": [
    "Y listo. Ya has desarrollado un modelo QSAR.\n",
    "Sin embargo, si no lo utilizamos, esto no es más que un objeto de Python sin utilidad práctica.\n",
    "Podemos comprobar que ha sido entrenado observando los coeficientes de la ecuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2mTLRK7_X1jl",
   "metadata": {
    "id": "2mTLRK7_X1jl"
   },
   "outputs": [],
   "source": [
    "#Visualiza los coeficientes\n",
    "print(\"Los coeficientes del modelo son: \", model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47787ddf",
   "metadata": {
    "id": "47787ddf"
   },
   "source": [
    "## Sección 2. Evaluación del rendimiento del modelo QSAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad5eb0",
   "metadata": {
    "id": "bdad5eb0"
   },
   "source": [
    "Una vez que un estimador ha sido ajustado, puede utilizarse para predecir el valor.\n",
    "En scikit-learn, esto se hace mediante otro método del estimador. Consulta la referencia:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "y utilízalo aquí para hacer una predicción sobre `X_train`.\n",
    "Guarda los valores predichos como `Y_train_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ow5ynSpRbPUP",
   "metadata": {
    "id": "ow5ynSpRbPUP"
   },
   "outputs": [],
   "source": [
    "#Predice los valores de Y en el juego de datos de entrenamiento\n",
    "Y_train_pred = _______________________\n",
    "\n",
    "#Visualiza las predicciones\n",
    "print(\"Las predicciones son: \", Y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b528b",
   "metadata": {
    "id": "482b528b"
   },
   "source": [
    "Como estamos prediciendo una serie de moléculas con actividades conocidas, podemos comparar los valores predichos con los valores experimentales u observados para evaluar la calidad del ajuste.\n",
    "En los modelos de clasificación, esto se hace comparando los valores observados y predichos para cada molécula y compilando la **matriz de confusión** (o **matriz de errores**).\n",
    "La matriz de confusión es una tabla en la que cada fila corresponde al valor **experimental u observado** y cada columna al valor **predicho**. Este es un ejemplo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0450a2",
   "metadata": {
    "id": "1b0450a2"
   },
   "source": [
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th></th>\n",
    "<th colspan=2>Predicted values</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th></th>    \n",
    "<th></th>\n",
    "<th>Negative</th>\n",
    "<th>Positive</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    \n",
    "<th rowspan=2>Observed values</th>   \n",
    "<th>Negative</th>\n",
    "<td>200</td>\n",
    "<td>2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Positive</th>\n",
    "<td>3</td>\n",
    "<td>150</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "Para rellenar la matriz, necesitamos contar el número de predicciones correctas e incorrectas, es decir, los valores predichos correctamente o incorrectamente, tanto para los casos positivos como para los negativos.\n",
    "\n",
    "Puedes escribir tu propio código a continuación para calcular manualmente los **falsos positivos (FP), falsos negativos (FN), verdaderos positivos (TP) y verdaderos negativos (TN)** comparando los valores de `Y_train` y `Y_train_pred`.\n",
    "Sin embargo, **scikit-learn** tiene una función que calcula automáticamente la matriz de confusión:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bD6awYNpNHHI",
   "metadata": {
    "id": "bD6awYNpNHHI"
   },
   "outputs": [],
   "source": [
    "data_length = len(Y_train)\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "TN=0\n",
    "\n",
    "for i in range(data_length):\n",
    "       if Y_train[i] ==  __ and Y_train_pred[i] == __:\n",
    "           TN=TN+1\n",
    "       elif Y_train[i] == __ and Y_train_pred[i] == __:\n",
    "           FN=FN+1\n",
    "       elif Y_train[i] == __ and Y_train_pred[i] == __:\n",
    "           TP=TP+1\n",
    "       elif Y_train[i] == __ and Y_train_pred[i] ==__:\n",
    "           FP=FP+1\n",
    "print('\\t\\tPositive\\tNegative')\n",
    "print('\\tPositive\\t'+str(TP)+'\\t'+str(FN))\n",
    "print('\\tNegative\\t'+str(FP)+'\\t'+str(TN))\n",
    "\n",
    "\n",
    "#Si no, puedes usar la función de sklearn.metrics para calcular la matriz de confusión\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Obtén la matriz de confusión\n",
    "conf_mat = confusion_matrix(Y_train,Y_train_pred)\n",
    "\n",
    "#Print as returned\n",
    "print(conf_mat)\n",
    "\n",
    "TP=conf_mat[1][1]\n",
    "TN=conf_mat[0][0]\n",
    "FP=conf_mat[0][1]\n",
    "FN=conf_mat[1][0]\n",
    "\n",
    "#More visual presentation\n",
    "print('\\t\\tNegative\\tPositive')\n",
    "print('\\tNegative\\t'+str(conf_mat[0][0])+'\\t'+str(conf_mat[0][1]))\n",
    "print('\\tPositive\\t'+str(conf_mat[1][0])+'\\t'+str(conf_mat[1][1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2bdca7",
   "metadata": {
    "id": "8b2bdca7"
   },
   "source": [
    "A continuación, hay varias métricas que pueden calcularse a partir de los valores de la matriz de confusión, como por ejemplo:\n",
    "\n",
    "* Exactitud (Accuracy): Fracción de valores correctamente asignados.\n",
    "\n",
    "* Sensibilidad o Recall: Fracción de positivos observados que se predicen correctamente.\n",
    "\n",
    "* Especificidad: Fracción de negativos observados que se predicen correctamente.\n",
    "\n",
    "* Precisión: Fracción de positivos predichos que son correctos.\n",
    "\n",
    "Completa el código de la siguiente celda para calcular estas métricas.\n",
    "\n",
    "Nota que hemos añadido un bloque try/except únicamente en el cálculo de la precisión.\n",
    "Esto se debe a que, mientras las demás métricas son fracciones sobre valores totales o positivos observados (siempre positivos), la precisión es una fracción sobre los positivos predichos.\n",
    "Potencialmente, un mal modelo podría predecir solo negativos y provocar un error de división por cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hLDw4sXBRkIq",
   "metadata": {
    "id": "hLDw4sXBRkIq"
   },
   "outputs": [],
   "source": [
    "#Write the equations using TP, FP, TN and FN from the previous cells.\n",
    "#Calcula las métricas de rendimiento usando las variables TP, FP, TN y FN\n",
    "accuracy = _____________\n",
    "sensitivity = _______________________\n",
    "specificity = ____________________\n",
    "try:\n",
    "    precision = ________________\n",
    "except:\n",
    "    precision = 0\n",
    "\n",
    "#Muestra en pantalla las métricas de rendimiento\n",
    "print('Accuracy:',round(accuracy,2))\n",
    "print('Sensitivity:',round(sensitivity,2))\n",
    "print('Specificity:',round(specificity,2))\n",
    "print('Precision:',round(precision,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KS_AJmUlTIJL",
   "metadata": {
    "id": "KS_AJmUlTIJL"
   },
   "source": [
    "En este caso, para simplificar el código y evitar errores, también puedes utilizar la implementación en `sklearn.metrics`.\n",
    "Ten en cuenta que la función para la sensibilidad se llama recall (otro nombre para la sensibilidad), y que la especificidad se obtiene usando también recall, pero añadiendo un parámetro que define el 0 como la clase positiva.\n",
    "\n",
    "Comprueba a continuación si tus métricas son correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B7uSCXogSn1O",
   "metadata": {
    "id": "B7uSCXogSn1O"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "\n",
    "#Calcula las métricas de rendimiento usando las funciones de sklearn.metrics y muestra en pantalla los resultados\n",
    "print('Accuracy:',round(accuracy_score(Y_train,Y_train_pred),2))\n",
    "print('Sensitivity:',round(recall_score(Y_train,Y_train_pred),2))\n",
    "print('Specificity:',round(recall_score(Y_train,Y_train_pred,pos_label=0),2))\n",
    "print('Precision:',round(precision_score(Y_train,Y_train_pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831f14d",
   "metadata": {
    "id": "1831f14d"
   },
   "source": [
    "## Sección 3: Validation con el juego de datos del test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b78ce",
   "metadata": {
    "id": "0d9b78ce"
   },
   "source": [
    "Mientras que la calidad del modelo sobre el conjunto de entrenamiento es una medida de la calidad del ajuste, el objetivo de un modelo QSAR es poder **predecir los valores de moléculas desconocidas** que están fuera del conjunto de datos.\n",
    "Por lo tanto, necesitamos **predecir los valores para el conjunto de prueba** y evaluar los resultados para determinar si el modelo es realmente predictivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd9541",
   "metadata": {
    "id": "2ecd9541"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_dataset = pd.read_csv('Earthworm_acute_toxicity_Test_RFE_logreg.csv',sep=',')\n",
    "\n",
    "X_test = test_dataset.iloc[:, 2:]\n",
    "Y_test = test_dataset[\"y\"]\n",
    "\n",
    "#NO ENTRENAMOS EL MODELO, SOLO PREDeCIMOS\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:',round(accuracy_score(Y_test,Y_test_pred),2))\n",
    "print('Sensitivity:',round(recall_score(Y_test,Y_test_pred),2))\n",
    "print('Specificity:',round(recall_score(Y_test,Y_test_pred,pos_label=0),2))\n",
    "print('Precision:',round(precision_score(Y_test,Y_test_pred),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ks6oTWldT_jR",
   "metadata": {
    "id": "ks6oTWldT_jR"
   },
   "source": [
    "En este caso, hemos obtenido un valor muy bueno para el conjunto de prueba, con una exactitud superior a la del entrenamiento.\n",
    "Esto puede ocurrir, incluso si el modelo se ha desarrollado únicamente con el conjunto de entrenamiento, pero podría ser una coincidencia debida a que el modelo esté **sesgado hacia ese conjunto de validación en particular**.\n",
    "\n",
    "Por lo tanto, es preferible utilizar un enfoque de **validación cruzada**, que combina diferentes divisiones de entrenamiento/prueba para evitar el sesgo de una división concreta.\n",
    "Vamos a utilizar el método `cross_validate`.\n",
    "\n",
    "Se pueden analizar varias métricas de rendimiento en los resultados de la validación cruzada, pero en este curso solo evaluaremos la **exactitud** (accuracy) tanto en el entrenamiento como en la prueba.\n",
    "Ten en cuenta que el conjunto de prueba en la validación cruzada **no corresponde con el conjunto de validación final**, sino con la fracción del conjunto de entrenamiento que se usó como prueba en cada iteración.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eU4sJ0THUz7x",
   "metadata": {
    "id": "eU4sJ0THUz7x"
   },
   "outputs": [],
   "source": [
    "#Importa la función cross_validate de sklearn.model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Aplica la función cross_validate al modelo y al conjunto de datos de entrenamiento y muestra los resultados\n",
    "cv_results = cross_validate(model, X_train, Y_train,scoring='accuracy',return_train_score=True)\n",
    "print('Train accuracy for the 5 submodels:', cv_results['train_score'])\n",
    "print('Test accuracy for the 5 submodels:', cv_results['test_score'])\n",
    "print('Mean accuracy:\\n\\tTRAIN:',round(cv_results['train_score'].mean(),3),'+/-',round(cv_results['train_score'].std(),3))\n",
    "print('\\tTEST:',round(cv_results['test_score'].mean(),3),'+/-',round(cv_results['test_score'].std(),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TJKogsLe21QG",
   "metadata": {
    "id": "TJKogsLe21QG"
   },
   "source": [
    "### **Q1** ¿Cuál es el valor de la exactitud (accuracy) de tu modelo en el conjunto de entrenamiento y en el conjunto de validación externa?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326ee16",
   "metadata": {
    "id": "9326ee16"
   },
   "source": [
    "## Sección 3. Optimización del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e10ca",
   "metadata": {
    "id": "ff5e10ca"
   },
   "source": [
    "En la sección anterior hemos visto cómo desarrollar y evaluar un modelo paso a paso.\n",
    "Sin embargo, no queremos simplemente construir cualquier modelo matemático, sino **desarrollar un modelo con un valor predictivo significativo**.\n",
    "Por eso, vamos a desarrollar diferentes modelos y seleccionar los mejores.\n",
    "\n",
    "En esta sección, tendrás una serie de tareas para desarrollar distintos modelos.\n",
    "Para poder compararlos fácilmente, vamos a utilizar una **función que automatice los pasos anteriores** en una sola función.\n",
    "\n",
    "Además, esta función almacenará **todas las métricas en un único diccionario**, lo que nos permitirá compararlas de forma sencilla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bef226",
   "metadata": {
    "id": "70bef226"
   },
   "outputs": [],
   "source": [
    "results={}\n",
    "\n",
    "\n",
    "def check_classification_model(model,train_file,test_file,name,save=True):\n",
    "    from sklearn.metrics import recall_score, accuracy_score, precision_score\n",
    "    #Primero carga los conjuntos de datos de entrenamiento y prueba\n",
    "    #y guarda los dataframes con los descriptores y los valores de la variable dependiente\n",
    "    train_dataset = pd.read_csv(train_file,sep=',')\n",
    "    X_train = train_dataset.iloc[:, 2:]\n",
    "    Y_train = train_dataset[\"y\"]\n",
    "\n",
    "    test_dataset = pd.read_csv(test_file,sep=',')\n",
    "    X_test = test_dataset.iloc[:, 2:]\n",
    "    Y_test = test_dataset[\"y\"]\n",
    "\n",
    "    #Ajusta el modelo a los datos de entrenamiento\n",
    "    model.fit(X_train,Y_train)\n",
    "\n",
    "    #Predice los valores de Y en el juego de datos de entrenamiento\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    tr_Accuracy=round(accuracy_score(Y_train,Y_train_pred),2)\n",
    "    tr_Sensitivity=round(recall_score(Y_train,Y_train_pred),2)\n",
    "    tr_Specificity=round(recall_score(Y_train,Y_train_pred,pos_label=0),2)\n",
    "    tr_Precision=round(precision_score(Y_train,Y_train_pred),2)\n",
    "    tr_cm=confusion_matrix(Y_train,Y_train_pred)\n",
    "\n",
    "    #Predice los valores de Y en el juego de datos de validación\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "    ts_Accuracy=round(accuracy_score(Y_test,Y_test_pred),2)\n",
    "    ts_Sensitivity=round(recall_score(Y_test,Y_test_pred),2)\n",
    "    ts_Specificity=round(recall_score(Y_test,Y_test_pred,pos_label=0),2)\n",
    "    ts_Precision=round(precision_score(Y_test,Y_test_pred),2)\n",
    "    ts_cm=confusion_matrix(Y_test,Y_test_pred)\n",
    "\n",
    "    #Realiza la validación cruzada y guarda solo la precisión del test\n",
    "    cv_results = cross_validate(model, X_train, Y_train,scoring='accuracy',return_train_score=True)\n",
    "    cv_Accuracy_mean=round(cv_results['test_score'].mean(),3)\n",
    "    cv_Accuracy_dev=round(cv_results['test_score'].std(),3)\n",
    "\n",
    "    if save:\n",
    "      results.update({name:[tr_Accuracy,tr_Sensitivity,tr_Specificity,tr_Precision,\n",
    "            ts_Accuracy,ts_Sensitivity,ts_Specificity,ts_Precision,\n",
    "            cv_Accuracy_mean,cv_Accuracy_dev]})\n",
    "\n",
    "    #Muestra en pantalla las métricas de rendimiento\n",
    "    print('\\t\\tTRAIN\\t\\t\\t\\tTEST')\n",
    "    print('\\t\\tNeg.\\tPos.\\t\\t\\tNeg.\\tPos.')\n",
    "    print('\\tNegative\\t'+str(tr_cm[0][0])+'\\t'+str(tr_cm[0][1])+'\\t\\tNegative\\t'+str(ts_cm[0][0])+'\\t'+str(ts_cm[0][1]))\n",
    "    print('\\tPositive\\t'+str(tr_cm[1][0])+'\\t'+str(tr_cm[1][1])+'\\t\\tPositive\\t'+str(ts_cm[1][0])+'\\t'+str(ts_cm[1][1]))\n",
    "    print('Accuracy:\\t',tr_Accuracy,'\\t\\t\\t\\t',ts_Accuracy)\n",
    "    print('Sensitivity:\\t',tr_Sensitivity,'\\t\\t\\t\\t',ts_Sensitivity)\n",
    "    print('Specificity:\\t',tr_Specificity,'\\t\\t\\t\\t',ts_Specificity)\n",
    "    print('Precision:\\t',tr_Precision,'\\t\\t\\t\\t',ts_Precision)\n",
    "    print('Cross validation test accuracy:',cv_Accuracy_mean,'+/-',cv_Accuracy_dev)\n",
    "\n",
    "    return [tr_Accuracy,tr_Sensitivity,tr_Specificity,tr_Precision,\n",
    "            ts_Accuracy,ts_Sensitivity,ts_Specificity,ts_Precision,\n",
    "            cv_Accuracy_mean,cv_Accuracy_dev]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qc4rgMJrvVKC",
   "metadata": {
    "id": "qc4rgMJrvVKC"
   },
   "source": [
    "Comencemos utilizando el mismo estimador que en las Secciones 1 y 2.\n",
    "Confirma que las métricas sean coherentes con los resultados obtenidos anteriormente.\n",
    "\n",
    "Mira el ejemplo a continuación sobre cómo usar esa función. Necesitas incluir 4 parámetros:\n",
    "\n",
    "* El objeto estimador (que debes crear y configurar fuera de la función)\n",
    "\n",
    "* El nombre del archivo con los datos de entrenamiento\n",
    "\n",
    "* El nombre del archivo con los datos de prueba\n",
    "\n",
    "* Un texto que se utilizará para etiquetar este modelo en los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kJFVw33Sd0zI",
   "metadata": {
    "id": "kJFVw33Sd0zI"
   },
   "outputs": [],
   "source": [
    "#Inicializa el objeto estimador de regresión logística\n",
    "estimator = LogisticRegression(C=0.5)\n",
    "#Aplica la función creada anteriormente\n",
    "metrics = check_classification_model(estimator,\n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv',\n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',\n",
    "                           'LogisticRegression_C5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00adcaa6",
   "metadata": {
    "id": "00adcaa6"
   },
   "source": [
    "### Sección 3.1 Modificación de hiperparámetros\n",
    "\n",
    "Los algoritmos utilizados para entrenar el modelo pueden ajustarse mediante la modificación de sus **hiperparámetros**.\n",
    "Los parámetros que se pueden utilizar dependen en gran medida de la **naturaleza del algoritmo**.\n",
    "En el caso de `LogisticRegression`, hay pocos parámetros que puedan ajustarse.\n",
    "\n",
    "En la ejecución original, asignamos un valor al parámetro `C`.\n",
    "Ahora, veamos qué ocurre utilizando el **valor por defecto**.\n",
    "\n",
    "¿El ajuste es **mejor o peor**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ziLsjSnLeLcv",
   "metadata": {
    "id": "ziLsjSnLeLcv"
   },
   "outputs": [],
   "source": [
    "#Inicializa el objeto estimador de regresión logística\n",
    "estimator = ____________\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv', \n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',  \n",
    "                           'LogisticRegression_default')  \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ed676",
   "metadata": {
    "id": "749ed676"
   },
   "source": [
    "Intenta modificar otro **hiperparámetro**, por ejemplo, puedes usar un `solver` distinto al predeterminado o cambiar el tipo de penalización utilizada\n",
    "(consulta la documentación de scikit-learn para ver ejemplos de valores posibles).\n",
    "\n",
    "¿El ajuste es **mejor o peor**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833b1e6",
   "metadata": {
    "id": "f833b1e6"
   },
   "outputs": [],
   "source": [
    "#Inicializa el objeto estimador de regresión logística\n",
    "estimator = \n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv', \n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',  \n",
    "                           _________________)  \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HuphJsVdq1oE",
   "metadata": {
    "id": "HuphJsVdq1oE"
   },
   "source": [
    "En este curso, para profundizar en la comprensión, vamos a explorar manualmente la modificación de los hiperparámetros.\n",
    "Sin embargo, existen formas automáticas de hacerlo, como GridSearchCV\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "Esta técnica no solo es una forma más eficiente de explorar varias combinaciones de hiperparámetros al mismo tiempo, sino que también utiliza una validación interna (mediante validación cruzada) para evaluar los modelos y elegir el mejor.\n",
    "\n",
    "Puedes probar este enfoque aquí y ver si el mejor estimador coincide con el que obtuviste manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckS9MEfMnEdk",
   "metadata": {
    "id": "ckS9MEfMnEdk"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "#Mantén la primera línea de código para evitar un output excesivo\n",
    "\n",
    "#Importa la función GridSearchCV de sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Selecciona los hiperparámetros a explorar con un diccionario\n",
    "params={'C':[0.5,1,10],'penalty':['l1','l2'],'solver':['lbfgs','newton-cg','sag']}\n",
    "\n",
    "grid_estimator=GridSearchCV(LogisticRegression(),params)\n",
    "\n",
    "#Ajusta el GridSearchCV al conjunto de datos de entrenamiento (Como si fuera un estimador normal)\n",
    "grid_estimator.fit(________________)\n",
    "\n",
    "#Muestra los hiperparámetros seleccionados (solo se muestran los no predeterminados)\n",
    "print(grid_estimator.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZttHOhOv8uuV",
   "metadata": {
    "id": "ZttHOhOv8uuV"
   },
   "source": [
    "Si no coincide con lo probado anteriormente, puedes utilizar la celda de abajo para examinar el modelo con los hiperparámetros propuestos por la función `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LfOeLn9J9Dv3",
   "metadata": {
    "id": "LfOeLn9J9Dv3"
   },
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(_______________________)\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv', \n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',  \n",
    "                           'LogisticRegression_GridSearch_Result') \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c8ed2",
   "metadata": {
    "id": "653c8ed2"
   },
   "source": [
    "### Sección 3.2 Cambiando el algoritmo: Support Vector Classifier\n",
    "\n",
    "\n",
    "Ahora vamos a probar un **algoritmo diferente**, en particular, vamos a utilizar el clasificador de **máquinas de vectores de soporte** (**Support Vector Machine**).\n",
    "Puedes encontrar más información sobre este algoritmo en:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Utilizando los mismos datos que anteriormente, intenta explorar en la celda de abajo distintos **hiperparámetros** para mejorar tu modelo.\n",
    "(Puedes hacer varias copias de la celda si deseas conservar diferentes versiones del modelo).\n",
    "\n",
    "Por ejemplo, puedes probar diferentes **kernels** (la función que transforma los descriptores para lograr una separación no lineal).\n",
    "¿Cuál de ellos da mejores resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db9f50",
   "metadata": {
    "id": "b9db9f50"
   },
   "outputs": [],
   "source": [
    "#Importa la función SVC de sklearn.svm\n",
    "from _______________ import SVC\n",
    "\n",
    "#Inicializa el estimador SVC\n",
    "estimator =  SVC(_______________)\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv',\n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv', \n",
    "                           'SVCClassifier') \n",
    "estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb8f76",
   "metadata": {
    "id": "98bb8f76"
   },
   "source": [
    "Después de experimentar un poco con el ejemplo, habrás visto que ciertos **hiperparámetros afectan a la exactitud** del modelo.\n",
    "\n",
    "Por ejemplo, el mejor **kernel** parece ser el **lineal**.\n",
    "Por tanto, a partir de ahora vamos a utilizar el **kernel lineal**, y a probar **distintos hiperparámetros para afinar tu modelo**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e-9MBK6u9w",
   "metadata": {
    "id": "c7e-9MBK6u9w"
   },
   "outputs": [],
   "source": [
    "#Inicializa el estimador SVC\n",
    "estimator =  SVC(kernel='linear',_______________)\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv',\n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv', \n",
    "                           'SVCClassifier_linear_more')  \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeebd74",
   "metadata": {
    "id": "bdeebd74"
   },
   "source": [
    "### Sección 3.3 Cambiando el algoritmo: Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a23647",
   "metadata": {
    "id": "e5a23647"
   },
   "source": [
    "Ahora vamos a explorar cómo el cambio de características (mediante los diferentes métodos de selección utilizados en la lección anterior) afecta a los modelos.\n",
    "En este caso, vamos a usar un algoritmo diferente, en particular un algoritmo basado en árboles: **Extra Trees**.\n",
    "\n",
    "En primer lugar, vamos a conocer un poco más sobre el comportamiento de este modelo utilizando los mismos descriptores que en los ejemplos anteriores.\n",
    "\n",
    "Utiliza la celda de abajo para evaluar el `ExtraTreesClassifier` con los hiperparámetros por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f8848",
   "metadata": {
    "id": "6c4f8848"
   },
   "outputs": [],
   "source": [
    "#Importa la función ExtraTreesClassifier de sklearn.ensemble\n",
    "from _______ import ExtraTreesClassifier\n",
    "\n",
    "#Inicializa el estimador ExtraTreesClassifier\n",
    "estimator =  _____________\n",
    "\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv',\n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',  \n",
    "                           'ExtraTreesClassifier_default') \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CT6YD5dBkf5B",
   "metadata": {
    "id": "CT6YD5dBkf5B"
   },
   "source": [
    "¿Qué opinas del rendimiento del modelo? Hemos visto que las métricas utilizadas en este curso van de 0 a 1. Si todos los valores son **1.0**, eso es perfecto, ¿verdad?\n",
    "\n",
    "En realidad, cuando las métricas en el conjunto de entrenamiento son **tan altas**, eso suele ser un **indicio de sobreajuste** (overfitting).\n",
    "Usando los hiperparámetros por defecto, el algoritmo `ExtraTrees` es capaz de reproducir perfectamente todos los datos de entrenamiento,\n",
    "pero probablemente esto se deba a la **gran capacidad de adaptación** del algoritmo y no a una relación realmente significativa.\n",
    "\n",
    "Vamos a ver en detalle el efecto de un **único hiperparámetro**.\n",
    "En el siguiente código se ejecuta un bucle que evalúa el modelo con distintos valores del parámetro `max_depth`.\n",
    "Este hiperparámetro controla la **profundidad máxima del árbol** (es decir, cuántas divisiones se pueden realizar).\n",
    "Valores bajos generan árboles más **simples y generalistas**.\n",
    "El valor por defecto no limita la profundidad, por lo que los árboles pueden crecer tanto como sea necesario.\n",
    "\n",
    "La próxima celda contiene código para recorrer distintos valores de esta variable y generar una serie de modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r65JL1T2jysw",
   "metadata": {
    "id": "r65JL1T2jysw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#La primera línea de código evita un output excesivo\n",
    "\n",
    "evol_res =[]\n",
    "for value in range(1,20):\n",
    "\n",
    "    estimator =  ExtraTreesClassifier(max_depth=value,random_state=2023)\n",
    "\n",
    "    res = check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv', \n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv',  \n",
    "                           'LogisticRegression_g'+str(value),\n",
    "                           save = False)  #Incluye esto para no guardar los resultados en el diccionario de resultados\n",
    "    evol_res.append(res+[value])\n",
    "res_df = pd.DataFrame(evol_res,columns=['ACC-tr','SENS-tr','SPEF-tr','PREC-tr','ACC-ts','SENS-ts','SPEF-ts','PREC-ts','ACC-CV','ACC-CV_dev','Variable'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782c071",
   "metadata": {
    "id": "7782c071"
   },
   "source": [
    "La celda anterior generará una salida considerable con los resultados de todos los modelos desarrollados en el bucle.\n",
    "Para evitar ruido innecesario, el texto de salida no se muestra y los modelos generados dentro del bucle no se incluyen en el diccionario de resultados.\n",
    "\n",
    "Por lo tanto, para ver qué ha ocurrido, por favor ejecuta la siguiente celda para visualizar los resultados en forma de gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f4631",
   "metadata": {
    "id": "f18f4631"
   },
   "outputs": [],
   "source": [
    "res_df1 = res_df[['ACC-tr','ACC-ts','ACC-CV','Variable']]\n",
    "res_df1.plot(legend=True,x='Variable',ylim=(-0.1,1.1)).legend(loc='center left',bbox_to_anchor=(1.0, 0.5));\n",
    "\n",
    "res_df2 = res_df[['SENS-tr','SENS-ts','Variable']]\n",
    "res_df2.plot(legend=True,x='Variable',ylim=(-0.1,1.1)).legend(loc='center left',bbox_to_anchor=(1.0, 0.5));\n",
    "\n",
    "res_df3 = res_df[['SPEF-tr','SPEF-ts','Variable']]\n",
    "res_df3.plot(legend=True,x='Variable',ylim=(-0.1,1.1)).legend(loc='center left',bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_tis3TK4v1O7",
   "metadata": {
    "id": "_tis3TK4v1O7"
   },
   "source": [
    "Como puedes ver, al aumentar este valor, el rendimiento en el entrenamiento eventualmente alcanza un valor perfecto,\n",
    "pero el rendimiento en el conjunto de prueba no mejora después de cierto punto (e incluso puede empeorar).\n",
    "\n",
    "Para poder comparar los efectos de las características (features), vamos a utilizar una combinación de hiperparámetros que reduzca significativamente la capacidad de adaptación del algoritmo.\n",
    "Si lo deseas, más adelante puedes explorar otras combinaciones, pero por favor, utiliza ahora los siguientes hiperparámetros para asegurar la reproducibilidad:\n",
    "\n",
    "* Profundidad máxima (`max_depth`) = 4\n",
    "\n",
    "* Número de estimadores (`n_estimators`) = 15\n",
    "\n",
    "* Mínimo de muestras para dividir (`min_samples_split`) = 4\n",
    "\n",
    "* `random_state` = 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aYvfp_wPxc0Z",
   "metadata": {
    "id": "aYvfp_wPxc0Z"
   },
   "outputs": [],
   "source": [
    "#Inicializa el estimador ExtraTreesClassifier con los hiperparámetros indicados\n",
    "estimator =  ExtraTreesClassifier(__________________)\n",
    "\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           'Earthworm_acute_toxicity_Train_RFE_logreg.csv', \n",
    "                           'Earthworm_acute_toxicity_Test_RFE_logreg.csv', \n",
    "                           'ExtraTreesClassifier_4_4_15_2023_RFE_logreg') \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec55854",
   "metadata": {
    "id": "7ec55854"
   },
   "source": [
    "¿Recuerdas los diferentes métodos de selección de características utilizados en la lección anterior?\n",
    "Utiliza distintos archivos de entrada para leer los descriptores adecuados y comprobar los resultados.\n",
    "\n",
    "En primer lugar, vamos a mantener el mismo algoritmo (**RFE**), pero esta vez vamos a comprobarlo utilizando el **estimador basado en árboles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I71qNE9DSkif",
   "metadata": {
    "id": "I71qNE9DSkif"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#Inicializa el estimador ExtraTreesClassifier con los mismos hiperparámetros que antes\n",
    "estimator =  ExtraTreesClassifier(_______________)\n",
    "\n",
    "#Llama a la función con los archivos adecuados\n",
    "check_classification_model(estimator, \n",
    "                           ______________, \n",
    "                           ______________,  \n",
    "                           'ExtraTreesClassifier_4_4_15_2023_RFE_dectree')  \n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4652271d",
   "metadata": {
    "id": "4652271d"
   },
   "source": [
    "## Sección 4. Comparación de los modelos\n",
    "\n",
    "Puedes usar el siguiente código para convertir el diccionario con los resultados en un DataFrame, y así visualizar la comparación de los métodos desarrollados según las métricas guardadas en `results_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10add65",
   "metadata": {
    "id": "f10add65"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results,columns=['Train Accuracy','Train Sensitivity','Train Specificity','Train Precision','Test Accuracy','Test Sensitivity','Test Specificity','Test Precision','CV Accuracy','CV Accuracy dev'],orient='index')\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TIyhZKHQh30V",
   "metadata": {
    "id": "TIyhZKHQh30V"
   },
   "source": [
    "Si quieres guardar esta información para utilizarla más adelante, puedes usar la celda de abajo para guardar este DataFrame como un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N_f-DYiIiwZY",
   "metadata": {
    "id": "N_f-DYiIiwZY"
   },
   "outputs": [],
   "source": [
    "#Guarda el dataframe en un archivo CSV\n",
    "results_df._______(________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1147ec",
   "metadata": {
    "id": "3c1147ec"
   },
   "source": [
    "La selección de un buen modelo no es una tarea fácil ni automática. Debemos tener en cuenta tanto el rendimiento en el conjunto de entrenamiento como en el de prueba, por ejemplo.\n",
    "Una buena predicción en el entrenamiento puede ser señal de sobreajuste, especialmente si el rendimiento en el conjunto de prueba es significativamente más bajo.\n",
    "\n",
    "Por otro lado, una predicción demasiado buena en el conjunto de prueba (sobre todo si es mejor que en el entrenamiento) podría indicar un sesgo hacia ese conjunto de datos específico, lo cual no se espera que se generalice.\n",
    "Por esta razón, es conveniente comprobar la robustez del modelo usando un enfoque de validación cruzada.\n",
    "\n",
    "Además, es útil diferenciar entre pruebas internas, que se utilizan para guiar la optimización del modelo y pueden afectar su desarrollo, y pruebas externas de validación, que consisten en conjuntos de datos independientes del desarrollo del modelo.\n",
    "\n",
    "Por otra parte, en un modelo de clasificación es interesante evaluar el comportamiento por separado de los valores positivos y negativos, especialmente en conjuntos de datos desequilibrados.\n",
    "Como hemos visto anteriorment, existen diversas métricas que combinan los resultados para ofrecer una estimación más equilibrada del rendimiento.\n",
    "En nuestro caso, vamos a usar solo la exactitud (accuracy), pero conviene comprobar que la especificidad y la sensibilidad también sean razonables.\n",
    "\n",
    "Por ahora, vamos a aplicar un criterio muy simple y seleccionaremos el método que tenga la mejor exactitud en la validación cruzada.\n",
    "De esta forma, no tomamos en cuenta el test externo y usamos una medida más robusta.\n",
    "\n",
    "Escribe un código que ordene los diferentes métodos de mejor a peor según esa columna, para así seleccionar el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0EOM0N5DL1KP",
   "metadata": {
    "id": "0EOM0N5DL1KP"
   },
   "outputs": [],
   "source": [
    "#Ordena los valores según la precisión del CV del juego de datos de validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d1352",
   "metadata": {
    "id": "7c0d1352"
   },
   "source": [
    "Vuelve a crear de nuevo el modelo en la celda de abajo para asegurarte de que el estimador es el correcto y que las métricas son las que esperabas.\n",
    "Además, revisa cuidadosamente las demás métricas para comprobar que el modelo sea adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E33bRxuUMBEB",
   "metadata": {
    "id": "E33bRxuUMBEB"
   },
   "outputs": [],
   "source": [
    "#Inicializa el estimador seleccionado\n",
    "estimator = _____________________\n",
    "\n",
    "check_classification_model(estimator, \n",
    "                           _________, \n",
    "                           ________,  \n",
    "                           'Final')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "avLLBdb_-dEF",
   "metadata": {
    "id": "avLLBdb_-dEF"
   },
   "source": [
    "### **Q4.** ¿Cuál es el rendimiento del modelo seleccionado? ¿Cuáles son las características relevantes del modelo (algoritmo, hiperparámetros, descriptores seleccionados, etc.)?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oaf8Ig850dqfp2VVyhn4YucQ4wYAOM7i",
     "timestamp": 1684842248158
    },
    {
     "file_id": "https://github.com/mpalominoschaetzlein/Python_QSAR_course/blob/main/Module2_QSAR_model_1_Classification.ipynb",
     "timestamp": 1683798218234
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
